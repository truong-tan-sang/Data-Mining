\section{Xây dựng mô hình dự đoán}

\subsection{Các đại lượng đánh giá mô hình}
Để đánh giá chất lượng và độ chính xác của các mô hình trong việc dự đoán bệnh tim (bài toán phân loại nhị phân), nhóm em sử dụng một tập hợp các đại lượng (metrics) đo lường phổ biến, tất cả đều được tính toán từ Ma trận nhầm lẫn (Confusion Matrix).

\subsubsection{Ma trận nhầm lẫn (Confusion Matrix)}
Ma trận nhầm lẫn là một bảng 2x2 mô tả hiệu suất của mô hình phân loại, cung cấp cái nhìn chi tiết về các trường hợp dự đoán đúng và sai:
\begin{itemize}
    \item \textbf{True Positive (TP):} Dự đoán là Bệnh (1) và thực tế là Bệnh (1). Đây là kết quả mong muốn nhất -- phát hiện đúng người bệnh.
    \item \textbf{True Negative (TN):} Dự đoán là Bình thường (0) và thực tế là Bình thường (0). Mô hình đúng khi nhận diện người khỏe mạnh.
    \item \textbf{False Positive (FP):} Dự đoán là Bệnh (1) nhưng thực tế là Bình thường (0). (Sai lầm Loại I -- ``Cảnh báo giả''). Trong y tế, FP dẫn đến xét nghiệm thêm không cần thiết, gây lo lắng và tốn kém, nhưng ít nguy hiểm hơn FN.
    \item \textbf{False Negative (FN):} Dự đoán là Bình thường (0) nhưng thực tế là Bệnh (1). (Sai lầm Loại II -- ``Bỏ sót bệnh'' -- cực kỳ nguy hiểm). Trong chẩn đoán bệnh tim, FN có thể dẫn đến hậu quả nghiêm trọng vì bệnh nhân không được điều trị kịp thời.
\end{itemize}

\textbf{Phân tích thêm:} Ma trận nhầm lẫn là nền tảng để tính toán tất cả các chỉ số đánh giá khác. Trong bối cảnh y tế, việc phân tích chi tiết bốn ô trong ma trận giúp xác định loại sai lầm nào mô hình đang mắc phải và cần cải thiện. Đối với bệnh tim, mục tiêu ưu tiên là \textit{giảm thiểu FN} (tăng khả năng phát hiện bệnh) ngay cả khi phải chấp nhận tăng nhẹ FP.

\subsubsection{Accuracy (Độ chính xác)}
Đo lường tỷ lệ phần trăm các dự đoán đúng (cả TP và TN) trên tổng số dự đoán.
\begin{equation}
    Accuracy = \frac{TP + TN}{TP + TN + FP + FN}
\end{equation}
\textbf{Ý nghĩa:} Accuracy là chỉ số tổng quan dễ hiểu nhất, cho biết tỷ lệ mô hình dự đoán chính xác. Chỉ số này hữu ích khi dữ liệu cân bằng (số lượng hai lớp gần bằng nhau). 

\textbf{Hạn chế quan trọng:} Accuracy có thể gây hiểu lầm khi dữ liệu mất cân bằng. Ví dụ: nếu trong tập dữ liệu có 95\% bệnh nhân là ``Bình thường'' và chỉ 5\% ``Bệnh tim'', một mô hình ngây thơ luôn dự đoán ``Bình thường'' cũng đạt 95\% accuracy, nhưng hoàn toàn vô dụng vì bỏ sót 100\% ca bệnh. Do đó, trong y tế, Accuracy không đủ để đánh giá mô hình -- cần kết hợp với Precision, Recall và F1-Score để có cái nhìn toàn diện về hiệu suất từng lớp.

\textbf{Trong bài toán này:} Dữ liệu Heart Disease tương đối cân bằng (tỷ lệ bệnh/không bệnh gần 50:50 như đã phân tích ở Chương EDA), nên Accuracy vẫn là một chỉ số tham khảo hữu ích, nhưng nhóm vẫn ưu tiên F1-Score và Recall để đảm bảo không bỏ sót bệnh.

\subsubsection{Precision (Độ chuẩn xác)} 
Đo lường tỷ lệ các dự đoán ``Bệnh'' (dương tính) thực sự là bệnh. Nói cách khác, trong tất cả các ca mô hình cảnh báo ``có bệnh'', bao nhiêu phần trăm là đúng?
\begin{equation}
    Precision = \frac{TP}{TP + FP}
\end{equation}
\textbf{Ý nghĩa:} Precision cao nghĩa là mô hình ít dự đoán nhầm người bình thường thành bệnh (ít FP -- ít ``cảnh báo giả''). 

\textbf{Khi nào Precision quan trọng?} Precision đặc biệt quan trọng khi chi phí của False Positive cao. Ví dụ: nếu sau mỗi cảnh báo dương tính cần thực hiện các xét nghiệm đắt tiền hoặc xâm lấn (chụp CT, thông tim, v.v.), Precision thấp sẽ gây lãng phí tài nguyên y tế và gây căng thẳng tâm lý cho bệnh nhân.

\textbf{Trade-off:} Tuy nhiên, trong chẩn đoán bệnh tim, việc bỏ sót bệnh (FN) nguy hiểm hơn cảnh báo giả (FP). Do đó, ta có thể chấp nhận Precision thấp hơn một chút để đổi lấy Recall cao hơn (phát hiện nhiều ca bệnh hơn). Đây là lý do nhóm sử dụng F1-Score -- một thước đo cân bằng giữa Precision và Recall -- để tối ưu hóa mô hình.

\subsubsection{Recall (Độ nhạy / Sensitivity)}
Đo lường tỷ lệ các ca Bệnh (dương tính) thực tế mà mô hình phát hiện được. Nói cách khác, trong tất cả người thực sự bị bệnh tim, mô hình phát hiện được bao nhiêu phần trăm?
\begin{equation}
    Recall = \frac{TP}{TP + FN}
\end{equation}
\textbf{Ý nghĩa:} Recall (còn gọi là Sensitivity hoặc True Positive Rate) là chỉ số \textit{cực kỳ quan trọng} trong chẩn đoán y tế. Recall cao nghĩa là mô hình bỏ sót rất ít ca bệnh (FN thấp).

\textbf{Tại sao Recall quan trọng nhất trong y tế?} Trong chẩn đoán bệnh tim, hậu quả của việc bỏ sót một ca bệnh (FN) rất nghiêm trọng: bệnh nhân không được điều trị kịp thời, có thể dẫn đến biến chứng nguy hiểm hoặc tử vong. Ngược lại, nếu cảnh báo nhầm một người khỏe mạnh là bệnh (FP), hậu quả chỉ là phải làm thêm xét nghiệm để xác nhận -- tốn kém và bất tiện nhưng không đe dọa tính mạng.

\textbf{Mục tiêu ưu tiên:} Do đó, trong sàng lọc và chẩn đoán ban đầu, mục tiêu là đạt Recall cao (lý tưởng \(\geq 0.90\) hoặc 90\%), nghĩa là phát hiện được ít nhất 90\% ca bệnh thực tế. Các ca dương tính sau đó sẽ được xác nhận bằng các xét nghiệm chuyên sâu hơn. Đây là nguyên tắc ``Better safe than sorry'' (an toàn hơn là hối tiếc) trong y học.

\textbf{Lưu ý:} Nếu chỉ tối đa hóa Recall, mô hình có thể đoán mọi người đều bệnh (Recall = 100\% nhưng Precision rất thấp). Vì vậy cần cân bằng với Precision thông qua F1-Score.

\subsubsection{F1-Score}
Là trung bình điều hòa (harmonic mean) của Precision và Recall, cung cấp một chỉ số cân bằng duy nhất để đánh giá tổng thể hiệu suất mô hình.
\begin{equation}
    F1-Score = 2 \times \frac{Precision \times Recall}{Precision + Recall}
\end{equation}
\textbf{Ý nghĩa:} F1-Score chỉ đạt giá trị cao khi \textit{cả hai} Precision và Recall đều cao. Nếu một trong hai chỉ số thấp, F1-Score sẽ bị kéo xuống đáng kể.

\textbf{Tại sao dùng trung bình điều hòa?} Khác với trung bình cộng thông thường, trung bình điều hòa ``trừng phạt'' các giá trị thấp nghiêm khắc hơn. Ví dụ: nếu Precision = 0.9 và Recall = 0.5, trung bình cộng là 0.7 (có vẻ ổn), nhưng F1-Score chỉ = 0.643 (phản ánh đúng vấn đề Recall quá thấp). Điều này đảm bảo mô hình không thể ``gian lận'' bằng cách chỉ tối ưu một chỉ số mà bỏ qua chỉ số còn lại.

\textbf{Tại sao F1-Score là thước đo chính?} 
\begin{itemize}
    \item \textbf{Cân bằng hai mục tiêu:} F1 đảm bảo mô hình vừa phát hiện nhiều bệnh (Recall cao), vừa không cảnh báo giả quá nhiều (Precision hợp lý).
    \item \textbf{Phù hợp dữ liệu gần cân bằng:} Khi tỷ lệ hai lớp tương đối đồng đều (như bài toán này), F1-Score là thước đo tin cậy và công bằng.
    \item \textbf{Dễ so sánh:} Một con số duy nhất giúp so sánh hiệu suất giữa các mô hình (Logistic Regression, KNN, Decision Tree, Random Forest) một cách khách quan.
\end{itemize}

\textbf{Kết luận:} Đây là thước đo chính mà nhóm sử dụng để lựa chọn và so sánh các mô hình. Mô hình có F1-Score cao nhất trên tập kiểm tra sẽ được coi là mô hình tốt nhất, vì nó đạt được sự cân bằng tối ưu giữa khả năng phát hiện bệnh và độ tin cậy của cảnh báo.

%-------------------------------------------------------
% Bắt đầu các mô hình
%-------------------------------------------------------

\subsection{Mô hình Hồi quy Logistic (Logistic Regression)}
\label{sec:model-lr}
Mô hình đầu tiên được xây dựng là Hồi quy Logistic, đóng vai trò là mô hình cơ sở (baseline) cho bài toán phân loại này. Do mô hình này nhạy cảm với thang đo, các đặc trưng đầu vào đã được chuẩn hóa bằng \texttt{StandardScaler}.

\subsubsection{Các chỉ số đánh giá hiệu suất mô hình}
Mô hình được tinh chỉnh (tuning) siêu tham số \texttt{C} (độ mạnh của regularization) bằng \texttt{GridSearchCV}. Hiệu suất của mô hình tốt nhất trên tập kiểm tra (test set) được ghi nhận như sau:
\begin{itemize}
    \item \textbf{Accuracy:} [Điền Accuracy, ví dụ: 0.8689]
    \item \textbf{Precision:} [Điền Precision, ví dụ: 0.8857]
    \item \textbf{Recall:} [Điền Recall, ví dụ: 0.8986]
    \item \textbf{F1-Score:} [Điền F1-Score, ví dụ: 0.8921]
\end{itemize}
\textbf{Nhận xét:} Mô hình baseline Hồi quy Logistic cho kết quả F1-Score rất tốt, cho thấy mối quan hệ giữa các đặc trưng và biến mục tiêu có thể được phân tách tuyến tính ở mức độ cao.

\subsubsection{Trực quan hóa kết quả}
Hình \ref{fig:cm-lr} cho thấy Ma trận nhầm lẫn của mô hình Hồi quy Logistic.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.6\textwidth]{images/hinh-cm-lr.png}
    \caption{Ma trận nhầm lẫn - Hồi quy Logistic (Tuned).}
    \label{fig:cm-lr}
\end{figure}

%-------------------------------------------------------

\subsection{Mô hình K-Nearest Neighbors (KNN)}
\label{sec:model-knn}
Mô hình thứ hai là K-Láng giềng Gần nhất, một thuật toán phi tuyến tính. Tương tự Hồi quy Logistic, KNN yêu cầu chuẩn hóa đặc trưng bằng \texttt{StandardScaler}.

\subsubsection{Thông số và hiệu suất mô hình KNN}
Phần chính của mô hình này là tìm ra số láng giềng $k$ tối ưu.
\begin{itemize}
    \item \textbf{Elbow Method:} (Như Hình \ref{fig:knn-elbow}) cho thấy Error Rate giảm dần và ổn định khi $k$ tăng, gợi ý $k$ tối ưu nằm trong khoảng [ví dụ: 15-24].
    \item \textbf{GridSearchCV:} Nhóm đã chạy tìm kiếm toàn diện cho \texttt{n\_neighbors}, \texttt{weights} ('uniform', 'distance') và \texttt{metric} ('euclidean', 'manhattan').
    \item \textbf{Kết quả (Tuned):} Tổ hợp tốt nhất [ví dụ: k=23, weights='distance', metric='manhattan'] đạt hiệu suất trên tập kiểm tra:
        \begin{itemize}
            \item \textbf{F1-Score:} [Điền F1-Score, ví dụ: 0.8912]
        \end{itemize}
\end{itemize}
\textbf{Nhận xét:} Hiệu suất của KNN (sau khi tuning) gần như tương đương với Hồi quy Logistic, cho thấy mô hình phi tuyến tính này hoạt động hiệu quả nhưng không vượt trội hơn baseline.

\subsubsection{Trực quan hóa kết quả mô hình KNN}

\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth]{images/hinh-knn-elbow.png}
    \caption{Biểu đồ Elbow Method cho thấy Error Rate theo giá trị K.}
    \label{fig:knn-elbow}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.6\textwidth]{images/hinh-cm-knn.png}
    \caption{Ma trận nhầm lẫn - KNN (Tuned).}
    \label{fig:cm-knn}
\end{figure}

%-------------------------------------------------------

\subsection{Mô hình Cây Quyết định (Decision Tree)}
\label{sec:model-dt}
Đây là mô hình dựa trên quy tắc, có ưu điểm lớn là khả năng diễn giải (interpretable) và không yêu cầu chuẩn hóa dữ liệu.

\subsubsection{Các chỉ số đánh giá hiệu suất mô hình}
Mô hình Cây Quyết định rất dễ bị overfitting (học thuộc lòng).
\begin{itemize}
    \item \textbf{Mô hình mặc định (Chưa cắt tỉa):} Đạt F1-Score (Train) = 1.0000, nhưng F1-Score (Test) chỉ đạt [ví dụ: 0.79xx]. Đây là dấu hiệu rõ ràng của overfitting.
    \item \textbf{Mô hình đã Cắt tỉa (Tuned):} Sử dụng \texttt{GridSearchCV} để tìm \texttt{max\_depth}, \texttt{min\_samples\_split} và \texttt{min\_samples\_leaf}. Mô hình tốt nhất đạt hiệu suất:
        \begin{itemize}
            \item \textbf{F1-Score:} [Điền F1-Score, ví dụ: 0.8810]
        \end{itemize}
\end{itemize}
\textbf{Nhận xét:} Việc cắt tỉa (pruning) đã cải thiện đáng kể khả năng tổng quát hóa của mô hình, đưa F1-Score (Test) tăng lên đáng kể.

\subsubsection{Phân tích độ quan trọng của đặc trưng (Feature Importances)}
Đây là kết quả quan trọng nhất của mô hình này cho môn Khai phá Dữ liệu (phục vụ Decision Making). Hình \ref{fig:dt-importance} cho thấy các yếu tố ảnh hưởng nhất.

\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth]{images/hinh-dt-importance.png}
    \caption{Độ quan trọng của đặc trưng - Cây Quyết định.}
    \label{fig:dt-importance}
\end{figure}

\textbf{Nhận xét:} Biểu đồ cho thấy \texttt{ST\_Slope} (Độ dốc ST) là yếu tố dự đoán quan trọng nhất, theo sau là \texttt{ChestPainType} (Loại đau ngực) và \texttt{MaxHR} (Nhịp tim tối đa).

\subsubsection{Trực quan hóa kết quả và cấu trúc cây}
\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth]{images/hinh-dt-tree.png}
    \caption{Trực quan hóa 3 tầng đầu tiên của Cây Quyết định (Tuned). Các nút hiển thị điều kiện chia, chỉ số Gini, số lượng mẫu (samples) và dự đoán tại nút đó.}
    \label{fig:dt-tree}
\end{figure}

%-------------------------------------------------------

\subsection{Mô hình Rừng ngẫu nhiên (Random Forest)}
\label{sec:model-rf}
Mô hình cuối cùng là Random Forest, một phương pháp ensemble (tập hợp) kết hợp nhiều cây quyết định để giảm overfitting và tăng độ ổn định.

\subsubsection{Các chỉ số đánh giá hiệu suất mô hình}
\begin{itemize}
    \item \textbf{Mô hình mặc định (100 cây):} Đã cho kết quả F1-Score (Test) là [ví dụ: 0.89xx], tốt hơn Decision Tree mặc định, cho thấy khả năng chống overfitting tự nhiên.
    \item \textbf{Mô hình đã Tinh chỉnh (Tuned):} Sử dụng \texttt{GridSearchCV} để tìm \texttt{n\_estimators}, \texttt{max\_depth}, \texttt{min\_samples\_leaf}. Mô hình tốt nhất đạt hiệu suất:
        \begin{itemize}
            \item \textbf{F1-Score:} [Điền F1-Score, ví dụ: 0.9015]
        \end{itemize}
\end{itemize}
\textbf{Nhận xét:} Random Forest cho hiệu suất cao nhất trong 4 mô hình, xác nhận sức mạnh của các phương pháp ensemble.

\subsubsection{Phân tích độ quan trọng của đặc trưng (Feature Importances)}
Feature Importance từ Random Forest thường được coi là ổn định và đáng tin cậy hơn so với một cây đơn lẻ.

\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth]{images/hinh-rf-importance.png}
    \caption{Độ quan trọng của đặc trưng - Rừng ngẫu nhiên.}
    \label{fig:rf-importance}
\end{figure}

\textbf{Nhận xét:} Kết quả từ Random Forest (Hình \ref{fig:rf-importance}) củng cố phát hiện của Decision Tree: \texttt{ST\_Slope}, \texttt{ChestPainType}, \texttt{MaxHR} và \texttt{Oldpeak} là những yếu tố dự đoán quan trọng nhất.

\subsubsection{Trực quan hóa kết quả}
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.6\textwidth]{images/hinh-cm-rf.png}
    \caption{Ma trận nhầm lẫn - Random Forest (Tuned).}
    \label{fig:cm-rf}
\end{figure}